{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1GWOSBqO5LWBD9t2C2GZ7ls6TN9pLEd3s","authorship_tag":"ABX9TyOccqjG4054DqbOXEiq9SmR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Loading libraries"],"metadata":{"id":"L2pt3NgwEGVM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bCizVpKksXj"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import  LSTM, Dense, Normalization, Dropout, Conv1D, Flatten\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","from tensorflow import keras\n","import kerastuner\n","from kerastuner.tuners import Hyperband\n","from tensorflow.keras import backend as K\n","import tensorflow as tf\n","import csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8fESx5O3K_mu"},"outputs":[],"source":["merged_data_short = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/merged_data_short.csv\")\n"]},{"cell_type":"markdown","source":["# Sampling 50 stations for hyperparametertuning"],"metadata":{"id":"hBahDv0cCxi4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iaJCMAybJy8u"},"outputs":[],"source":["# Sampling 50 unique station IDs at random\n","random_stations = merged_data_short['station_id_encoded'].drop_duplicates().sample(n=50, random_state=42)\n","\n","# Include these stations from the dataset\n","merged_data_short_sample = merged_data_short[merged_data_short['station_id_encoded'].isin(random_stations)]\n"]},{"cell_type":"markdown","source":["# Splitting data"],"metadata":{"id":"Zayw0q9uC4tD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hX0FR1XAJy8w"},"outputs":[],"source":["# Sort by 'date'\n","merged_data_short_sorted = merged_data_short_sample.sort_values(by=['date', 'station_id_encoded', 'hour'])\n","\n","merged_data_short_sorted.drop(columns=[\"station_name\", \"short_name\"], inplace=True)\n","\n","merged_data_short_sorted.reset_index(drop=True, inplace=True)\n","\n","# Split sorted data into features (X) and target (y)\n","X_sorted = merged_data_short_sorted.drop('start_count', axis=1)\n","y_sorted = merged_data_short_sorted['start_count']\n","\n","# Splitting on date\n","train_end_index = X_sorted[X_sorted['date'] == '2022-11-30'].index[-1]\n","val_end_index = X_sorted[X_sorted['date'] == '2023-03-10'].index[-1]\n","\n","# Split the data manually\n","X_train = X_sorted.iloc[:train_end_index]\n","y_train = y_sorted.iloc[:train_end_index]\n","X_val = X_sorted.iloc[train_end_index:val_end_index]\n","y_val = y_sorted.iloc[train_end_index:val_end_index]\n","X_test = X_sorted.iloc[val_end_index:]\n","y_test = y_sorted.iloc[val_end_index:]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Er3WY9h0Jy8w"},"outputs":[],"source":["X_train.drop(columns=[\"date\"], inplace=True)\n","X_val.drop(columns=[\"date\"], inplace=True)\n","X_test.drop(columns=[\"date\"], inplace=True)\n"]},{"cell_type":"markdown","source":["# Standardizing columns"],"metadata":{"id":"9kv0Sy5YDCVp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RmQyGjSbJy8x"},"outputs":[],"source":["# Feature columns to be standardized\n","feature_columns = [\"hour\", \"capacity\", \"longitude\", \"latitude\", \"temperature_2m (°C)\",\n","                   \"relativehumidity_2m (%)\", \"precipitation (mm)\", \"snowfall (cm)\",\n","                   \"cloudcover (%)\", \"direct_radiation (W/m²)\", \"windspeed_10m (km/h)\",\n","                   \"bike_lane_length_km\", \"restaurants_count\", \"rail_stations_count\",\n","                   \"universities_count\", \"bus_stations_count\", \"businesses_count\", \"parks_count\"]\n","\n","# Create the Normalization layer and adapt it to the training data\n","standardizer = tf.keras.layers.Normalization(axis=-1)\n","standardizer.adapt(X_train[feature_columns])\n","\n","# Apply the standardizer to the training data\n","X_train[feature_columns] = standardizer(X_train[feature_columns].values)\n","\n","# Apply the standardizer to the validation data\n","X_val[feature_columns] = standardizer(X_val[feature_columns].values)\n","\n","# Apply the standardizer to the test data\n","X_test[feature_columns] = standardizer(X_test[feature_columns].values)\n","\n","# Create the Normalization layer and adapt it to the training data\n","target_standardizer = tf.keras.layers.Normalization(axis=-1)\n","target_standardizer.adapt(y_train[['start_count']])\n","\n","# Apply the standardizer to the training data target variable\n","y_train['start_count'] = target_standardizer(y_train[['start_count']])\n","\n","# Apply the standardizer to the validation data target variable\n","y_val['start_count'] = target_standardizer(y_val[['start_count']])\n","\n","# Apply the standardizer to the test data target variable\n","y_test['start_count'] = target_standardizer(y_test[['start_count']])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YfQz4OzN7IWc"},"source":["# Batch generator hyperparametertuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":517,"status":"ok","timestamp":1699991087256,"user":{"displayName":"Rob van der Wielen","userId":"16334711937746181770"},"user_tz":-60},"id":"wuft5_EwP3ii","outputId":"bc5f88ff-38f8-411a-efa7-0309b5be3014"},"outputs":[{"data":{"text/plain":["((256, 24, 42), (256,))"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["def batch_generator(X, y, time_steps=24, batch_size=256, infinite_loop=True):\n","    total_size = len(X) - time_steps\n","    start_idx = 0\n","\n","    while True:\n","        X_batch = np.zeros((batch_size, time_steps, X.shape[1]))\n","        y_batch = np.zeros((batch_size,))\n","\n","        for i in range(batch_size):\n","            if start_idx + time_steps <= total_size:\n","                X_batch[i] = X.iloc[start_idx:start_idx + time_steps].values\n","                y_batch[i] = y.iloc[start_idx + time_steps]\n","                start_idx += 1\n","            else:\n","                if infinite_loop:\n","                    start_idx = 0\n","                else:\n","                    break\n","\n","        yield (X_batch, y_batch)\n","\n","        if not infinite_loop and start_idx + time_steps > total_size:\n","            break\n","\n","# Small batch size to keep memory usage low\n","batch_size = 256\n","\n","train_gen = batch_generator(X_train, y_train, time_steps=24, batch_size=256, infinite_loop=True)\n","val_gen = batch_generator(X_val, y_val, time_steps=24, batch_size=256, infinite_loop=True)\n","test_gen = batch_generator(X_test, y_test, time_steps=24, batch_size=256, infinite_loop=False)\n","\n","# Test the generator to see if it yields batches correctly\n","X_batch, y_batch = next(train_gen)\n","(X_batch.shape, y_batch.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"dSM01rBp7N9n"},"source":["# Hyperparametertuning LSTM model"]},{"cell_type":"markdown","source":["## Defining LSTM model"],"metadata":{"id":"PViOXo_LDbh7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-UGohbgp7FzY"},"outputs":[],"source":["def rmse(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n","\n","input_shape = (24, X_batch.shape[2])\n","\n","def build_lstm_model(hp):\n","    num_units = hp.Int('num_units', min_value=32, max_value=128, step=32)\n","    drop_out = hp.Choice('drop_out', [0.2, 0.4, 0.6])\n","    optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n","    lstm_layers = hp.Choice('lstm_layers', [1, 2])\n","    include_dense = hp.Choice('include_dense', [False, True])\n","\n","    model = Sequential()\n","    model.add(LSTM(units=num_units, return_sequences=True if lstm_layers == 2 else False, input_shape=input_shape))\n","    model.add(Dropout(drop_out))\n","\n","    if lstm_layers == 2:\n","        model.add(LSTM(units=num_units))\n","        model.add(Dropout(drop_out))\n","\n","    if include_dense:\n","        dense_units = hp.Int('dense_units', min_value=32, max_value=128, step=32)\n","        model.add(Dense(dense_units, activation='relu'))\n","\n","    model.add(Dense(1))\n","\n","    # Define the optimizer\n","    if optimizer_choice == 'adam':\n","        learning_rate = hp.Choice('adam_learning_rate', [0.1, 0.01, 0.001])\n","        optimizer = Adam(learning_rate=learning_rate, clipvalue=1.0)\n","    elif optimizer_choice == 'sgd':\n","        learning_rate = hp.Choice('sgd_learning_rate', [0.1, 0.01, 0.001])\n","        optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n","    elif optimizer_choice == 'rmsprop':\n","        learning_rate = hp.Choice('rmsprop_learning_rate', [0.1, 0.01, 0.001])\n","        optimizer = RMSprop(learning_rate=learning_rate)\n","\n","    model.compile(optimizer=optimizer, loss='mse', metrics=['mae', rmse])\n","\n","    model.summary()\n","    return model"]},{"cell_type":"markdown","source":["## Tuning using Hyperband and batch generator"],"metadata":{"id":"bwRXT03sDc9x"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lsYntPl6QS8C"},"outputs":[],"source":["tuner = Hyperband(\n","    build_lstm_model,\n","    objective='val_loss',\n","    max_epochs=5,\n","    directory='/content/drive/MyDrive/Colab Notebooks/model_7',\n","    project_name='hyperband_lstm_tuning',\n","    factor=3,\n","    hyperband_iterations=2\n","\n",")\n","stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0C0lzUie_r_"},"outputs":[],"source":["# Calculate the number of steps per epoch\n","steps_per_epoch = (len(X_train) - 24) // batch_size\n","validation_steps = (len(X_val) - 24) // batch_size\n","\n","# During the hyperparameter tuning search, pass these as arguments\n","tuner.search(\n","    train_gen,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=val_gen,\n","    validation_steps=validation_steps,\n","    epochs=5,\n","    callbacks=[stop_early]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ifuCUTw4lKKp"},"outputs":[],"source":["# Get the hyperparameters of the best model\n","best_hyperparameters = tuner.get_best_hyperparameters()[0]\n","print('Best hyperparameters:', best_hyperparameters.values)"]},{"cell_type":"markdown","source":["## Saving hyperparameters"],"metadata":{"id":"cCZ5GFRqDplN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjL2UpYLeNuA"},"outputs":[],"source":["best_hyperparameters = tuner.get_best_hyperparameters()[0]\n","\n","# Define the file name for the CSV\n","filename = '/content/drive/MyDrive/Colab Notebooks/best_hyperparameters.csv'\n","\n","# Open the file in write mode\n","with open(filename, 'w', newline='') as csvfile:\n","    csvwriter = csv.writer(csvfile)\n","    csvwriter.writerow(['Hyperparameter', 'Value'])\n","    for key, value in best_hyperparameters.values.items():\n","        csvwriter.writerow([key, value])"]},{"cell_type":"markdown","metadata":{"id":"k81I-FeG89GQ"},"source":["# Hyperparametertuning CNN-LSTM model"]},{"cell_type":"markdown","source":["## Defining CNN-lSTM model"],"metadata":{"id":"RjRQkpNhDvt1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDs4HprJ9Fl2"},"outputs":[],"source":["# Define RMSE function\n","def rmse(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n","\n","# Define Input shape\n","input_shape = (24, X_batch.shape[2])\n","\n","\n","def build_cnn_lstm_model(hp):\n","    model = Sequential()\n","    model.add(Conv1D(\n","        filters=hp.Int('filters_1', min_value=32, max_value=128, step=32),\n","        kernel_size=hp.Choice('kernel_size_1', values=[3, 5]),\n","        activation='relu',\n","        input_shape=input_shape\n","    ))\n","\n","    # Optional Second Conv1D layer\n","    C2 = hp.Int('filters_2', min_value=0, max_value=128, step=32)\n","    if C2 > 0:\n","        model.add(Conv1D(\n","            filters=C2,\n","            kernel_size=hp.Choice('kernel_size_2', values=[3, 5]),\n","            activation='relu'\n","        ))\n","\n","    model.add(LSTM(\n","        units=hp.Int('units', min_value=30, max_value=90, step=20),\n","        activation='relu'\n","    ))\n","\n","    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.6, step=0.2)))\n","\n","    # Optional Additional Dense layer(s)\n","    for i in range(hp.Int('num_dense_layers', 1, 2)):\n","        model.add(Dense(\n","            units=hp.Int(f'dense_{i+1}_units', min_value=10, max_value=100, step=20),\n","            activation='relu'\n","        ))\n","\n","    model.add(Dense(1))\n","\n","    # Optimizer choice and learning rate setup remains the same\n","    optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n","    if optimizer_choice == 'adam':\n","        learning_rate = hp.Choice('adam_learning_rate', [0.1, 0.01, 0.001])\n","        optimizer = Adam(learning_rate=learning_rate, clipvalue=1.0)\n","    elif optimizer_choice == 'sgd':\n","        learning_rate = hp.Choice('sgd_learning_rate', [0.1, 0.01, 0.001])\n","        optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n","    elif optimizer_choice == 'rmsprop':\n","        learning_rate = hp.Choice('rmsprop_learning_rate', [0.1, 0.01, 0.001])\n","        optimizer = RMSprop(learning_rate=learning_rate)\n","\n","    # Compile model\n","    model.compile(optimizer=optimizer, loss='mse', metrics=['mae', rmse])\n","\n","    model.summary()\n","    return model\n"]},{"cell_type":"markdown","source":["## Tuning using Hyperband and batch generator"],"metadata":{"id":"Gn0mwtzMD5P-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaQeAf5z9FqW"},"outputs":[],"source":["# Initialize the Hyperband tuner\n","tuner = Hyperband(\n","    build_cnn_lstm_model,\n","    objective='val_loss',\n","    max_epochs=5,\n","    directory=\"/content/drive/MyDrive/Colab Notebooks/Good/CNN_LSTM_Tuning_2\",\n","    project_name='hyperband_lstm_tuning',\n","    factor=3,\n","    hyperband_iterations=2\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RkGp2jqJ9NeL"},"outputs":[],"source":["# Calculate the number of steps per epoch\n","steps_per_epoch = (len(X_train) - 24) // batch_size\n","validation_steps = (len(X_val) - 24) // batch_size\n","\n","tuner.search(\n","    train_gen,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=val_gen,\n","    validation_steps=validation_steps,\n","    epochs=5,\n","    callbacks=[stop_early]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k_oIRkzL9WXZ"},"outputs":[],"source":["# Get the hyperparameters of the best model\n","best_hyperparameters = tuner.get_best_hyperparameters()[0]\n","print('Best hyperparameters:', best_hyperparameters.values)"]},{"cell_type":"markdown","source":["## Saving hyperparameters"],"metadata":{"id":"KbqkzeTbEBH3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iRCoF0-89Fvo"},"outputs":[],"source":["best_hyperparameters = tuner.get_best_hyperparameters()[0]\n","\n","# Define the file name for the CSV\n","filename = '/content/drive/MyDrive/Colab Notebooks/best_hyperparameters.csv'\n","\n","# Open the file in write mode\n","with open(filename, 'w', newline='') as csvfile:\n","    csvwriter = csv.writer(csvfile)\n","    csvwriter.writerow(['Hyperparameter', 'Value'])\n","    for key, value in best_hyperparameters.values.items():\n","        csvwriter.writerow([key, value])\n"]}]}
