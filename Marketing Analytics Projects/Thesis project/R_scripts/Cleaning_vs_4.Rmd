---
title: "Cleaning"
output: html_document
date: "2023-03-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#--- Loading packages ---#

```{r}
install.packages("dplyr")
install.packages("tidyr")
install.packages("stringr")
```

#--- Loading libraries ---#

```{r}
library(dplyr)
library(tidyr)
library(stringr)
```

#--- Loading in the datasets ---#

*I first load in the dataset with the rank information of Netflix and its competitors using the read.csv function. The empty fields get NA as value. I do the same for the dataset with the video information* 

```{r}
# Load in dataset
rank_info <- read.csv("C:/Users/Systeembeheer/OneDrive - Tilburg University/Documenten/Master/Marketing Analytics/Thesis/ThesisRob/ThesisRob/Datasets/Raw_data/rank_information_comp_vs6.csv", sep = ";", na.strings=c("", "NA"))
summary(rank_info)

# Load in dataset
video_info <- read.csv("C:/Users/Systeembeheer/OneDrive - Tilburg University/Documenten/Master/Marketing Analytics/Thesis/ThesisRob/ThesisRob/Datasets/Raw_data/video_information4.csv", sep = ";", na.strings=c("", "NA"))
summary(video_info)


```

*The first datset has 5069 observations, this is 131 rows less than expected. This is because flixpatrol for Disney+ not always gave the entire top 10, but less videos. But for the analysis this does not really matter, because I am just going to count the number of videos with similar characteristics. The Netflix data is complete for every week.*

*The second dataset has 5062 rows. These are 5 rows less as the first dataset. This is probably because there were some errors at certain rows when using the API that were ignored, as was adviced on the internet. I am going to use left_join on these dataset by using the title, so this should also not matter if all rows are complete.*


#--- Cleaning video_info  ---#

*I start with cleaning the dataset that contains information about the video, like the genre and mpaa rating*

# Delete the duplicated in video_info

*I used all the titles that were scraped to get the video information via the IMDbpy API. This wasn't necessary, because I only need the video characteristics for every movie once. So, to join the datasets together I only need the unique rows. So I remove all the duplicate rows in this dataset.*

```{r}
# removing duplicates
video_info <- video_info[!duplicated(video_info), ]

```

# Check if every title only occurs once now
```{r}
# check title occurrences
video_check <- video_info %>%
  group_by(title.name) %>%
   count(title.name)
video_check
```
*When I checked if all the titles are now unique I still found some duplicate titles with different values for the MPAA rating and the online rating. These are only five titles and to keep it simple I will delete these rows and add the right values by hand*

# Removing the five duplicate titles
```{r}
# removing duplicate videos
video_info <- video_info %>%
  filter(!title.name == "God Forbid: The Sex Scandal That Brought Down a Dynasty")%>%
  filter(!title.name == "Bling Ring: Hollywood Heist")%>%
  filter(!title.name == "Dragon Ball Super: Broly")%>%
  filter(!title.name == "Limitless with Chris Hemsworth")%>%
  filter(!title.name == "Tammy")
```

# Adding the right five titles
```{r}
# creating new rows
video_info <- video_info %>% 
  add_row(title.name = "God Forbid: The Sex Scandal That Brought Down a Dynasty", genre = "Documentary,", MPAA_rating = "TV-MA,", rating = 6.8) %>%
  add_row(title.name = "Bling Ring: Hollywood Heist", genre = "Documentary,Crime,History,", MPAA_rating = "TV-MA,", rating = 5.7) %>%
  add_row(title.name = "Dragon Ball Super: Broly", genre = "Animation,Action,Adventure,Family,Fantasy,Sci-Fi,", MPAA_rating = "PG,", rating = 7.7) %>% 
  add_row(title.name = "limitless with chris hemswordt", genre = "Documentary,Adventure,", MPAA_rating = "TV-14,", rating = 8.1) %>%
  add_row(title.name = "Tammy", genre = "Comedy,Romance,", MPAA_rating = "R,", rating = 4.9)
tail(video_info)
```

*Looks good*

# Removing comma at the end of every string for variables Genre, and MPAA
*While scraping the data I put a comma between every genre and MPAA rating level. However, by doing this, there was also a comma placed at the end of each string. With the code below this comma is removed again.*

```{r}
# remove the comma at the end of each value in the genre and MPAA_rating variable
library(stringr)
video_info$MPAA_rating <- str_sub(video_info$MPAA_rating, 1, nchar(video_info$MPAA_rating)-1)
video_info$genre <- str_sub(video_info$genre, 1, nchar(video_info$genre)-1)
head(video_info)

```

# Keep rows
```{r}
keep_genres <- video_info %>%
   select(title.name, genre)
```

## Dummy code the genre variable
*In this step I dummy code the genre variable for the entire dataset, this makes it easier for me to work with this variable*
```{r}
# dummy code genre
video_info <- video_info %>% separate_rows(genre, sep = ',') %>% mutate(val = 1) %>% 
  pivot_wider(names_from = genre, values_from = val, values_fill = list(val = 0)) 
head(video_info)
```


# Dummy code the MPAA_rating varaible
*Somehow when I try to dummy code the MPAA_rating variable, still get an error that says that there are duplicates, which means I can't dummy code this variable. So I added two steps in between that solve this problem.*
```{r}
# dummy code MPAA
video_info_2 <- video_info %>% separate_rows(MPAA_rating, sep = ',') %>% mutate(val = 1) %>% 
    group_by(title.name, MPAA_rating) %>%
    summarise(val = sum(val)) %>%
        pivot_wider(names_from = MPAA_rating, values_from = val, values_fill = list(val = 0))

```

*For some videos IMDB gave the same MPAA multiple times to this single video. In this analysis every rating is only counted once. So all the dummy coded fields that got more than one get a one assigned to them. These were a few instances and with the following simple code this is resolved.* 
```{r}
# all MPAA dummies get the value, 1.
video_info_2[video_info_2 == 2] <- 1
video_info_2[video_info_2 == 3] <- 1
video_info_2[video_info_2 == 4] <- 1
video_info_2[video_info_2 == 12] <- 1

```

# Joining genre and MPAA_rating dataset together
*With the code below I will use left_join to merge the video_info dataset, which contains the genre dummies and the other information, with the video_info_2 dataset, which contain the MPAA rating dummies. In the second step I will remove the old MPAA rating column that still was in the dataset after merging.*
```{r}
#join all dummies
video_info <- video_info %>% left_join(video_info_2, 
           by=c('title.name'))

# remove the old MPAA_rating column
video_info <- video_info %>%
  select(!MPAA_rating)
head(video_info)
```

#--- Joining datasets ---#

# Joining datasets (rank_info & video_info) together
*Now that the video_info dataset is cleaned I will merge the video_info data set, which contains the dummy-coded genres, dummy-coded MPAA ratings and the online ratings, with the rank_info data set, which contains information about the rank of each title and some additional information.* 

```{r}
# join datasets together
video_information_all_platforms <- rank_info %>% left_join( video_info, 
           by=c('title.name'))
head(video_information_all_platforms)
```

#--- Cleaning new video_information dataset ---#

# Cleaning MPAA rating 
*The levels X, F, 12, AO, Approved, Passed, 13+, T, MA-17 & 16+ of MPAA rating all have only a maximum of four instances assigned to them. Also these levels are all used together with another level of the MPAA rating. These classifications are used very little and do not say more than the classification of which they are combined with. For sake of simplicity, these columns are removed.* 

```{r}
# removing irrelevant levels of the MPAA rating
remove_col <- c("X", "F", "12", "AO", "Approved", "Passed", "13+", "16+", "T", "MA-17", "TV-13")

video_information_all_platforms <- video_information_all_platforms %>%
  select(!remove_col)
colnames(video_information_all_platforms)
```

*When a cabinet line is used in the variable name I get many errors. Therefore I will use underscores in the column names where a cabinet line is used*
```{r}
# change columns names

colnames(video_information_all_platforms)[39] <- "PG_13"
colnames(video_information_all_platforms)[40] <- "TV_PG"
colnames(video_information_all_platforms)[41] <- "TV_14"
colnames(video_information_all_platforms)[43] <- "TV_MA"
colnames(video_information_all_platforms)[46] <- "Not_rated"
colnames(video_information_all_platforms)[47] <- "TV_Y"
colnames(video_information_all_platforms)[48] <- "TV_G"
colnames(video_information_all_platforms)[49] <- "TV_V7_FV"
colnames(video_information_all_platforms)[50] <- "TV_Y7"
colnames(video_information_all_platforms)[51] <- "NC_17"
```

# Merging MPAA rating dummy columns
*The other dummy columns for MPAA_rating are now divided in the television programming rating system (TV-...), which are for TV-shows, and the MPAA (Motion Picture Association of America) rating system, which are for movies and are used by film studios and streaming services. The meaning of the classifications are mostly the same. Therefore the classification will be merged together. The following classification will be used: G - General Audiences (G, TV-Y, TV-G), PG - Parental Guidance Suggested (PG, TV-Y7, TV-Y7-FV, TV-PG), PG-13 - Parents Strongly Cautioned (PG - 13, TV-14, TV-13), R - Restricted (R), NC - 17 - Adults only (NC - 17, TV-MA) & Not rated (Not Rated, Unrated, NA) (motionpictures, n.d.; tvguidelines, n.d.). The videos that got NA will fall under Not Rated videos*

```{r}
# creating merged groups of MPAA ratings
video_information_all_platforms_cleaned <- video_information_all_platforms %>%
  mutate(G_General_audiences = ifelse(G == 1 | TV_Y == 1 | TV_G == 1, 1, 0),
         PG_Parental_guidance_suggested = ifelse(PG == 1 | TV_Y7 == 1 | TV_V7_FV == 1 | TV_PG ==1, 1, 0),
         PG13_Parents_strongly_cautioned = ifelse(PG_13 == 1 | TV_14 == 1, 1, 0),
         NC17_Adults_only = ifelse(NC_17 == 1 | TV_MA == 1, 1, 0),
         Not_Rated = ifelse(Not_rated == 1 | Unrated == 1 | NA.y == 1, 1, 0))
```

# Drop old MPAA rating dummy columns
*I drop all the old columns, because they are now joined together into new columns. Also I drop the column NA.x for the genre dummies, because this is an empty column.*
```{r}
#drop old columns
col_to_drop <- c("G", "TV_Y", "TV_G","PG", "TV_Y7","TV_V7_FV", "PG_13", "TV_14", "NC_17", "TV_MA", "Not_rated", "Unrated", "NA.y", "TV_PG")

video_information_all_platforms_cleaned <- video_information_all_platforms_cleaned %>%
  select(!col_to_drop) %>%
  select(!NA.x)
colnames(video_information_all_platforms_cleaned)
```


# Changing video column names
*For the genre and MPAA dummies I will put a prefix in front of every variable name. I do this because than I can easily jointly refer to these variables, instead of referring to them all every time. Which is especially useful in the pivot_longer function* 
```{r}
# adding pre-fix to dummy genre and MPAA columns names
genre_columns <- paste("genre_", colnames(video_information_all_platforms_cleaned[10:36]))
genre_columns <- sub(" ", "", genre_columns)
MPAA_columns <- paste("mpaa_", colnames(video_information_all_platforms_cleaned[37:42]))
MPAA_columns <- sub(" ", "", MPAA_columns)

#assigning new names to the dataset
colnames(video_information_all_platforms_cleaned)[10:36] <- genre_columns
colnames(video_information_all_platforms_cleaned)[37:42] <- MPAA_columns

# the  MPAA level R got no change, so I still have to change this name to a more meaningful name.
colnames(video_information_all_platforms_cleaned)[37] <- "mpaa_R_Restricted"


colnames(video_information_all_platforms_cleaned)
```



```{r}
# join datasets together
video_information_all_platforms_cleaned_test <- video_information_all_platforms_cleaned %>% left_join(keep_genres, 
           by=c('title.name'))
head(video_information_all_platforms_cleaned_test)
```

```{r}
unwanted_genres <- c("Sport", "News", "War", "History", "Reality-TV", "Fantasy", 
                     "Game-Show", "Biography", "Short", "Documentary", "Film-Noir", 
                     "Music", "Western", "Musical", "Talk-Show", "Horror")

# remove unwanted genres and commas
video_information_all_platforms_cleaned_test <- video_information_all_platforms_cleaned_test %>%
  mutate(genre = gsub(paste(unwanted_genres, collapse = "|"), "", genre)) %>%
  mutate(genre = gsub("Adventure", "Action", genre)) %>%
  mutate(genre = gsub("Animation", "Family", genre)) %>%
  mutate(genre = gsub("Crime", "Suspense", genre)) %>%
  mutate(genre = gsub("Thriller", "Suspense", genre)) %>%
  mutate(genre = gsub("Mystery", "Suspense", genre)) %>%
  mutate(genre = gsub("^,|,$", "", genre)) %>% 
  mutate(genre = gsub(",{2,}", ",", genre)) %>% 
  mutate(genre = strsplit(genre, ",\\s*")) %>%
  mutate(genre = lapply(genre, unique)) %>%
  mutate(genre = sapply(genre, paste, collapse = ", ")) %>%
  mutate(genre = gsub("^,", "", genre)) %>%
  mutate(genre = ifelse(genre == "", "Other", genre)) %>%
  mutate(genre = str_replace_all(genre, "\\s+", ""))


```

#--- Creating dataset for descriptive analysis ---#

*Later for the descriptive analysis I have to create a data set that also includes all competitors. At this step the competitor data is cleaned and still complete. So I remove the columns that I do not need for the descriptive analysis and keep only the distinct rows to end up with the cleaned dataset for all platforms. I also write this data set to a csv to store it on my laptop to use it for the analysis later*
```{r}
video_information_all_platforms_cleaned_test$platform[video_information_all_platforms_cleaned_test$platform == 'Amazon'] <- 'Amazon Prime'

write.csv(video_information_all_platforms_cleaned_test, "C:/Users/Systeembeheer/OneDrive - Tilburg University/Documenten/Master/Marketing Analytics/Thesis/ThesisRob/ThesisRob/Datasets/Cleaned_data/all_platforms_cleaned.csv")
```

#--- Splitting data ---#

*Now that the data set is cleaned I will split it up in a data set for all Netflix' videos and a data set for all the competitor videos.*
```{r}
# create data set for Netflix' videos
netflix_data_wide <- video_information_all_platforms_cleaned_test %>%
  filter(platform == "Netflix")
head(netflix_data_wide)

# creating data set for competitor videos. 
competitor_data_wide <- video_information_all_platforms_cleaned_test %>%
  filter(platform != "Netflix")

head(competitor_data_wide)
  

```

#--- Transforming competitor dataset ---#

*The competitor data set does not need much cleaning. The only things that will be used in this dataset are the genre and MPAA rating, specifically I will count the number of videos with a certain genre and mpaa rating in a given week, which will be used later in transforming the data. To count the number of videos with a certain genre or MPAA rating it is use full to transfer the data into a long format. Now I will use the pre-fix "genre_" and "mpaa_" to refer to all dummy columns that relate to these variables.*

```{r}
competitor_data_wide <- competitor_data_wide %>%
  select(-c(10:36))
```


```{r}
# convert genre and MPAA rating dummy variables to long format
competitor_long <- competitor_data_wide %>%
    pivot_longer(cols = starts_with("genre_") | starts_with("mpaa_"),
               names_to = "genre_mpaa") %>%
  filter(value == 1)
head(competitor_long)
```
*now every title in this data set is split up by it's genre and MPAA rating. One row accounts for one level of the genre or MPAA rating.*

# Creating new dataset with total competitor genre and MPAA rating per week
*I now will create a new data set. This data set will show for every week in 2022 how many titles on all competitor platforms combined were featured in a chart list and contained a particular genre or MPAA rating. Later this dataset will be used to count the number of similar videos on Netflix*

```{r}
# creating a new dataset, which contains per genre and MPAA rating the total number of videos on competitor platforms (n) which contain that characteristic. 
num_videos_week_comp_genre <- competitor_data_wide %>%
  group_by(week_num) %>%
  count(genre) %>%
  rename(genre_n = n)

num_videos_week_comp_mpaa <- competitor_long %>%
  group_by(week_num) %>%
  count(genre_mpaa)

# something like, if genre_comp == genre_netflix += NN
```


#--- Transforming Netflix data ---#

*First I will add a variable to the Netflix dataset that tells what the first week was that the title appeared on the Netflix top 10. This will be useful later for transforming the seasonality variable.*
```{r}
# add variable first week
netflix_data <- netflix_data_wide %>%
  group_by(title.name) %>%
  mutate(first_week_num = min(week_num)) %>%
  ungroup()

#Put the first week column after the week number column.
netflix_data <- netflix_data %>% relocate(first_week_num, .after=week_num)
head(netflix_data)

```

*I will now create a dataset, that reports only the title and the week number. A title can occur multiple times in this dataset but with different week number. Every week number stands for a week that the title appeared on the Netflix top 10 in that week. This will be used for counting the instances with similar genre and MPAA as competitors later. This step is done at this point because the dataset in now still in the right format to perform this step.*

```{r}
# creating data file with only title and week of which the title appeared on the Netflix top 10
netflix_per_week <- netflix_data %>%
  select(title.name, week_num) %>%
  group_by(title.name)
head(netflix_per_week)
```


# Aggregating Netflix data to get the right DV
*Now for the Netflix data I only want to keep for every title the row with the highest rank, because that will be the dependent variable. So I will group by the title to only include every title once and slice by the highest rank.*

```{r}
# keep only the row with the highest rank for each title
netflix_data_cumulative_rank <- netflix_data %>%
  group_by(title.name) %>%
  top_n(1, cumulative_rank) %>%
  ungroup()

head(netflix_data_cumulative_rank)
```

# Transforming the exlusive variable
*The exclusive variable still contained "This title is Netflix original", which was used when scraping Flixpatrol. I will give the values that have this title a one and the other values a zero.*
```{r}
netflix_data_cumulative_rank <- netflix_data_cumulative_rank %>%
  mutate(exclusive = if_else(exclusive == "This title is Netflix original", 1, 0))

netflix_data_cumulative_rank[4]
```

# Transforming the type variable
*Also the type variable will be transformed into a dummy variable. Because this variable just has two levels, namely movies and TV-shows, the titles that are a movie get a 1 and the titles that are a TV-show get a 0.*

```{r}
netflix_data_cumulative_rank <- netflix_data_cumulative_rank %>%
  mutate(Type = if_else(Type == "Movies", 1, 0))
netflix_data_cumulative_rank[6]
```


# Tranforming format Netflix data
*Now I will also transform the format of the Netflix data to a long format, which makes it easier later to compare the genre and mpaa ratings to the once of competitors.*
```{r}
# convert genre and MPAA rating dummy variables to long format
netflix_long <- netflix_data_cumulative_rank %>%
  pivot_longer(cols = starts_with("mpaa_"), 
               names_to = "genre_mpaa",
               values_to = "value") %>%
  filter(value == 1)
head(netflix_long)
```

*now every title in this data set is split up by it's genre and MPAA rating. One row accounts for one level of the genre or MPAA rating.*


# Adding week numbers to long format
*Now I add the week number for every time a title occurred on the Netflix top 10. For this I will use the netflix_per_week dataset that was created earlier. Now every row reflects a genre or MPAA rating for every movie of a week that it was in the Netflix top 10. E.g., when a movie was in the top 10 in week 1 & 2, than every level of genre and MPAA rating is returned for both weeks.*
```{r}
# change week_num to last_week_num
colnames(netflix_long)[8] <- "last_week_num"


netflix_long <- netflix_long %>%
  left_join(netflix_per_week, by = c("title.name" = "title.name"))

head(netflix_long)
```

#--- Merging Netlfix_long data with competitor genre and MPAA count ---#

*I now will merge the number of competitor videos with a certain genre or a certain mpaa rating with the Netflix data set.* 

*When the n column has an NA, than that means that during that week there were no competitor videos with a similar genre or MPAA rating. So I  change the NA's to zero's, meaning no competitor videos.*

```{r}
netflix_merged_comp_1 <- netflix_long %>%
  distinct() %>%
  left_join(num_videos_week_comp_mpaa, by = c("week_num", "genre_mpaa")) %>%
  mutate(n_mpaa = ifelse(is.na(n), 0, n))
head(netflix_merged_comp_1)
```

```{r}
netflix_merged_comp <- netflix_merged_comp_1 %>%
  distinct() %>%
  left_join(num_videos_week_comp_genre, by = c("week_num", "genre")) %>%
  mutate(n_genre = ifelse(is.na(genre_n), 0, genre_n))
head(netflix_merged_comp)
```


*now in this dataset every row stands for a genre or mpaa rating in a given week that a video was popular with at the end the number of videos with that same level of genre or mpaa rating.*


# Calculating avg number of movies with certain genre/mpaa rating om compeitor platforms
*I now calculate for every video during the entire period it was on the Netflix top 10 the average number of movies with the same genre.* 

```{r}
# Calculating the avg number of competitor videos with certain genres during entire period on the Netflix top 10
AVG_number_same_genre <- netflix_merged_comp %>%
  group_by(title.name, week_num) %>%
  summarise(AVG_Ngenre_comp = sum(n_genre)) %>%
  group_by(title.name) %>%
  summarise(AVG_Ngenre_comp = mean(AVG_Ngenre_comp)) 

```


```{r}
# Calculating the avg number of competitor videos with certain MPAA during entire period on the Netflix top 10.

AVG_number_same_mpaa <- netflix_merged_comp %>%
  filter(str_detect(genre_mpaa, "mpaa_")) %>%
  group_by(title.name, week_num) %>%
  summarise(AVG_Nmpaa_comp = sum(n)) %>%
  group_by(title.name) %>%
  summarise(AVG_Nmpaa_comp = mean(AVG_Nmpaa_comp)) 
```
#--- Merge all datasets together ---#

*I now merge the Netflix data with the datasets that contain the average number of videos with certain genres or certain MPAA rating.*

```{r}
# merge datasets together
netflix_merged <- netflix_long %>%
  left_join(AVG_number_same_mpaa, by = "title.name") %>%
  left_join(AVG_number_same_genre, by = "title.name")
```


```{r}
# merge datasets together
netflix_merged <- netflix_merged %>%
  select(-c(11:37, 39))
```



# Transforming dataset to wide format again
*The dataset is now still in a long format. For my analysis I will transform it to a wide format again. Before I do this I first have to remove num_week, last_week_num and rank to make this work. These are also not relevant for the analysis and were nevertheless removed.*

```{r}
# Remove unnecessary columns
netflix_merged_without_week <- netflix_merged %>%
  select(!week_num) %>%
  select(!last_week_num) %>%
  select(!rank)

# Transform dataset to wider format again
netflix_merged_wider <- netflix_merged_without_week %>%
  distinct()
```

#Removing dummy variables
*Now that I have counted all movies, I will also remove the dummy variables for the genre and MPAA rating, because they are not needed anymore.*

# Seasonality moderator
*The next code is definitely not the most prettiest code, but functionally it works and it is fairly simple without mistakes. For the seasonality moderator I used the first week that the title appeared on the Netflix top 10. Why?*
```{r}
holidays <- c(22, 27, 47, 52)

one_week <- c(21, 23, 26, 28, 46, 48, 1, 51)
two_weeks <- c(20, 24, 25, 29, 45, 49, 2, 50)
three_weeks <- c(19, 30, 44, 3)
four_weeks <- c(18, 31, 43, 4)
five_weeks <- c(17, 32, 42, 5)
six_weeks <- c(16, 33, 41, 6)
seven_weeks <- c(15, 34, 40, 7)
eight_weeks <- c(14, 35, 39, 8)
nine_weeks <- c(13, 36, 38, 9)
ten_weeks <- c(12, 37, 10)
eleven_weeks <- c(11)

netflix_merged_wider <- netflix_merged_wider %>%
  mutate(Holiday_distance = case_when(
    first_week_num %in% holidays ~ 0,
    first_week_num %in% one_week ~ 1,
    first_week_num %in% two_weeks ~ 2,
    first_week_num %in% three_weeks ~ 3,
    first_week_num %in% four_weeks ~ 4,
    first_week_num %in% five_weeks ~ 5,
    first_week_num %in% six_weeks ~ 6,
    first_week_num %in% seven_weeks ~ 7,
    first_week_num %in% eight_weeks ~ 8,
    first_week_num %in% nine_weeks ~ 9,
    first_week_num %in% ten_weeks ~ 10, 
    first_week_num %in% eleven_weeks ~ 11))
```


# Exporting dataset to add sequel
*The sequel will be added by hand because this can be not found on IMDB or Flixpatrol.*

```{r}
netflix_sequel <- read.csv("C:/Users/Systeembeheer/OneDrive - Tilburg University/Documenten/Master/Marketing Analytics/Thesis/Thesis_R/netflix_merged_wider_vs2.csv", sep = ";")

# Somehow this dataset also got empty columns with it
netflix_sequel <- netflix_sequel[1:2]

# Left_join sequel
netflix_merged_wider <- netflix_merged_wider %>% left_join(netflix_sequel, 
           by=c('title.name'))
```


# Removing last columns
*In this last step I will remove the last columns that are not needed anymore. Which results in the final complete data set*

```{r}
#Removing columns that will not be used for analysis
netflix_data_complete <- netflix_merged_wider %>%
  select(!platform) %>%
  select(!first_week_num)
```

```{r}
# dummy code genre
netflix_data_complete <- netflix_data_complete %>% separate_rows(genre, sep = ',') %>% mutate(val = 1) %>% 
  pivot_wider(names_from = genre, values_from = val, values_fill = list(val = 0)) 
head(netflix_data_complete)
```


```{r}
# genres to keep

# remove the unwanted genre dummy columns
only_mpaa <- netflix_data_cumulative_rank %>%
  select(c(3, mpaa_R_Restricted:mpaa_Not_Rated)) %>%
  distinct()
```

```{r}
# merge the two datasets on a common column
netflix_data_complete <- merge(netflix_data_complete, only_mpaa, by.x = "title.name", by.y = "title.name")

netflix_data_complete <- netflix_data_complete %>%
  select(!value)
```

#--- Write to csv ---#
```{r}
write.csv(netflix_data_complete, "C:/Users/Systeembeheer/OneDrive - Tilburg University/Documenten/Master/Marketing Analytics/Thesis/ThesisRob/ThesisRob/Datasets/Cleaned_data/netflix_data_complete.csv")

```



